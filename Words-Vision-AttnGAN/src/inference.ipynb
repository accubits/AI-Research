{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanSolo/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: 'werkzeug.contrib.cache' is deprecated as of version 0.15 and will be removed in version 1.0. It has moved to https://github.com/pallets/cachelib.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from werkzeug.contrib.cache import SimpleCache\n",
    "cache = SimpleCache()\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "\n",
    "import model\n",
    "from model import RNN_ENCODER, G_NET, CNN_ENCODER, G_DCGAN, D_NET256\n",
    "from miscc.utils import weights_init\n",
    "from datasets import TextDataset, prepare_data\n",
    "from miscc.utils import build_super_images, build_super_images2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanSolo/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = G_NET()\n",
    "netG.apply(weights_init)\n",
    "netG.cuda()\n",
    "netG.eval()\n",
    "#\n",
    "text_encoder = RNN_ENCODER(27297, nhidden=256)\n",
    "state_dict = \\\n",
    "    torch.load('../models/text_encoder100.pth', map_location=lambda storage, loc: storage)\n",
    "text_encoder.load_state_dict(state_dict)\n",
    "text_encoder = text_encoder.cuda()\n",
    "text_encoder.eval()\n",
    "\n",
    "state_dict = \\\n",
    "    torch.load('../models/coco_AttnGAN2.pth', map_location=lambda storage, loc: storage)\n",
    "netG.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load filenames from: ../data/coco//train/filenames.pickle (82783)\n",
      "Load filenames from: ../data/coco//test/filenames.pickle (40470)\n",
      "Load from:  ../data/coco/captions.pickle\n"
     ]
    }
   ],
   "source": [
    "imsize = 64 * (2 ** (3 - 1))\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize(int(imsize * 76 / 64)),\n",
    "    transforms.RandomCrop(imsize),\n",
    "    transforms.RandomHorizontalFlip()])\n",
    "\n",
    "dataset = TextDataset('../data/coco/', 'test',\n",
    "                      base_size=64,\n",
    "                      transform=image_transform)\n",
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size,\n",
    "    drop_last=True, shuffle=True, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtoix = dataset.wordtoix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_img():\n",
    "    output=[]\n",
    "    '''generate images from example sentences'''\n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    data_dic = {}\n",
    "\n",
    "\n",
    "    sentences = ['There is a sun in the middle of the sky']\n",
    "    # a list of indices for a sentence\n",
    "    captions = []\n",
    "    cap_lens = []\n",
    "    for sent in sentences:\n",
    "        if len(sent) == 0:\n",
    "            continue\n",
    "        sent = sent.replace(\"\\ufffd\\ufffd\", \" \")\n",
    "        tokenizer = RegexpTokenizer(r'\\w+')\n",
    "        tokens = tokenizer.tokenize(sent.lower())\n",
    "        if len(tokens) == 0:\n",
    "            print('sent', sent)\n",
    "            continue\n",
    "\n",
    "        rev = []\n",
    "        for t in tokens:\n",
    "            t = t.encode('ascii', 'ignore').decode('ascii')\n",
    "            if len(t) > 0 and t in wordtoix:\n",
    "                rev.append(wordtoix[t])\n",
    "        captions.append(rev)\n",
    "        cap_lens.append(len(rev))\n",
    "    max_len = np.max(cap_lens)\n",
    "\n",
    "    sorted_indices = np.argsort(cap_lens)[::-1]\n",
    "    cap_lens = np.asarray(cap_lens)\n",
    "    cap_lens = cap_lens[sorted_indices]\n",
    "    cap_array = np.zeros((len(captions), max_len), dtype='int64')\n",
    "    for i in range(len(captions)):\n",
    "        idx = sorted_indices[i]\n",
    "        cap = captions[idx]\n",
    "        c_len = len(cap)\n",
    "        cap_array[i, :c_len] = cap\n",
    "    data_dic[0] = [cap_array, cap_lens, sorted_indices]\n",
    "    for key in data_dic:\n",
    "        save_dir = 'op/'\n",
    "        captions, cap_lens, sorted_indices = data_dic[key]\n",
    "\n",
    "        batch_size = captions.shape[0]\n",
    "        nz = 100\n",
    "\n",
    "        with torch.no_grad():\n",
    "            captions = Variable(torch.from_numpy(captions))\n",
    "            cap_lens = Variable(torch.from_numpy(cap_lens))\n",
    "\n",
    "            captions = captions.cuda()\n",
    "            cap_lens = cap_lens.cuda()\n",
    "\n",
    "        for i in range(1):  # 16\n",
    "            with torch.no_grad():\n",
    "                noise = Variable(torch.FloatTensor(batch_size, nz))\n",
    "                noise = noise.cuda()\n",
    "            #######################################################\n",
    "            # (1) Extract text embeddings\n",
    "            ######################################################\n",
    "            hidden = text_encoder.init_hidden(batch_size)\n",
    "            # words_embs: batch_size x nef x seq_len\n",
    "            # sent_emb: batch_size x nef\n",
    "            words_embs, sent_emb = text_encoder(captions, cap_lens, hidden)\n",
    "            mask = (captions == 0)\n",
    "            #######################################################\n",
    "            # (2) Generate fake images\n",
    "            ######################################################\n",
    "            noise.data.normal_(0, 1)\n",
    "            fake_imgs, attention_maps, _, _ = netG(noise, sent_emb, words_embs, mask)\n",
    "            # G attention\n",
    "            cap_lens_np = cap_lens.cpu().data.numpy()\n",
    "            for j in range(batch_size):\n",
    "                save_name = '%s/%d_s_%d' % (save_dir, i, sorted_indices[j])\n",
    "                for k in range(len(fake_imgs)):\n",
    "                    im = fake_imgs[k][j].data.cpu().numpy()\n",
    "                    im = (im + 1.0) * 127.5\n",
    "                    im = im.astype(np.uint8)\n",
    "                    # print('im', im.shape)\n",
    "                    im = np.transpose(im, (1, 2, 0))\n",
    "                    # print('im', im.shape)\n",
    "                    im = Image.fromarray(im)\n",
    "                    fullpath = '%s_g%d.png' % (save_name, k)\n",
    "                    output.append(im)\n",
    "\n",
    "                for k in range(len(attention_maps)):\n",
    "                    if len(fake_imgs) > 1:\n",
    "                        im = fake_imgs[k + 1].detach().cpu()\n",
    "                    else:\n",
    "                        im = fake_imgs[0].detach().cpu()\n",
    "                    attn_maps = attention_maps[k]\n",
    "                    att_sze = attn_maps.size(2)\n",
    "                    img_set, sentences = \\\n",
    "                        build_super_images2(im[j].unsqueeze(0),\n",
    "                                            captions[j].unsqueeze(0),\n",
    "                                            [cap_lens_np[j]], dataset.ixtoword,\n",
    "                                            [attn_maps[j]], att_sze)\n",
    "                    if img_set is not None:\n",
    "                        im = Image.fromarray(img_set)\n",
    "#                         fullpath = '%s_a%d.png' % (save_name, k)\n",
    "                        output.append(im)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/D4567C46567C2AFE/Work HDD/Research/AI-Research/Words-Vision-AttnGAN/src/miscc/utils.py:239: RuntimeWarning: invalid value encountered in true_divide\n",
      "  one_map = (one_map - minV) / (maxV - minV)\n"
     ]
    }
   ],
   "source": [
    "output = gen_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F3353DA2190>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
